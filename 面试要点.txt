1、HashMap和Hashtable有什么区别
	HashTable在java发布时提供键值映射的数据结构，线程安全，效率低
	HashMap是jdk1.2产生，不能保证映射的顺序在一段时间内保持不变，jdk1.5之后有了concurrent包
	HashMap和Hashtable都是基于哈希表实现的，每一个元素是一个key-value对，其内部通过单链表解决冲突问题，容量不足，自动增长
	父类不同：
		HashMap继承AbstractMap类，HashTable继承Dictionary,他们都同时实现map,Cloneable(可复制)，Serializable(可序列化)这三个接口
		Hashtable多提供了elements()和contains()两方法
	null值：
		Hashtable不支持Null key,不支持Null value
		HashMap中null可以作为键，但只能有一个，可以有一个或多个键所对应的值为null，不能用get()来判断是否有某个键，应该用containsKey()判断
	线程安全：
		Hashtable线程安全，每个方法都加入Synchronize方法，多线程用Hashtable，同步的，效率低
		HashMap不是线程安全，不是同步的，多线程下会死锁，效率高，单线程操作下好点，多需要多线程使用线程安全的ConcurrentHashMap使用了分段锁，并不是对整个数据进行锁定，效率高很多倍
	遍历方式不同：
		Hashtable、HashMap使用Iterator,Hashtable还使用了Enumeration方式
	初始容量不同：
		HashTable初始长度是11，之后每次扩充容量变为2n+1
		HashMap初始长度是16，之后每次扩充变为原来的两倍
		创建时候给定了容量初始值，Hashtable直接使用给定的大小，HashMap会扩充为2的幂次方
	计算哈希值的方法不同：
		Hashtable直接使用对象的hashCode，hashCode是JDK根据对象的地址或者字符串或者数字计算出来的int类型的数值，然后使用除留余数发来获得最终位置，非常耗时，效率低
		HashMap将哈希表的大小固定为2的幂，取模预算时，不需要做除法，只需要位运算，效率更高
2、HashMap实现原理
	HashMap是基于哈希表的Map接口的非同步实现，此实现提供所有可选的映射操作，并允许使用null值和null键，不保证映射的顺序，特别不保证该顺序恒久不变
	java中最基本的结构两种：数组和模拟指针（引用），HashMap就是链表散列的数据结构，即数组和链表的结合体，每一个数组中的值存放的是一个Entry类，属性有key，value，next，数组是HashMap的主体，链表则是为了解决哈希冲突而存在的
	实现原理：
		利用key的hashCode重新hash计算出当前对象的元素在数组中的下标
		存储时，如果出现hash值相同的key，此时有两种情况，如果key相同，则覆盖原始值，如果key不同，则将当前的key-value放入链表中
		获取时，直接找到hash值对应的下标，在进一步判断key是否相同，从而找到对应值
		理解了以上过程就明白HashMap如何解决hash冲突的问题，核心就是使用数组的存储方式，然后将冲突的key的对象放入链表中，一旦发现冲突就在链表中做进一步的对比

	1.7和1.8区别：
		1.7用的是头插法。用单链表进行的纵向延伸，当采用头插法时候容易出现逆序且环行链表死循环问题
		1.8用的是尾插法，因为加入了红黑树使用尾插法，能够避免出现逆序且链表死循环的问题
		扩容后数据存储位置的计算方式也不一样：
			jdk1.7的时候是直接用hash值和需要扩容的二进制数进行&，先扩容再put
			jdk1.8直接用了jdk1.7时候计算的规律，也就是扩容前的原始位置+扩容的大小值=jdk1.8的计算方式，这种方式只需要判断Hash值的新增参与运算的位是0还是1就直接迅速计算出了扩容后的存储方式，先put再扩容

	红黑树和链表的区别
		jdk8以后链表长度大于等于7的时间引入红黑树


	参考答案：
		HashMap 基于 Hash 算法实现，通过 put(key,value) 存储，get(key) 来获取 value
		当传入 key 时，HashMap 会根据 key，调用 hash(Object key) 方法，计算出 hash 值，根据 hash 值将 value 保存在 Node 		对象里，Node 对象保存在数组里
		当计算出的 hash 值相同时，称之为 hash 冲突，HashMap 的做法是用链表和红黑树存储相同 hash 值的 value
		当 hash 冲突的个数：小于等于 8 使用链表；大于 8 时，使用红黑树解决链表查询慢的问题
	ps：
		上述是 JDK 1.8 HashMap 的实现原理，并不是每个版本都相同，比如 JDK 1.7 的 HashMap 是基于数组 + 链表实现，所以 hash 冲		突时链表的查询效率低
		hash(Object key)  方法的具体算法是 (h = key.hashCode()) ^ (h >>> 16)，经过这样的运算，让计算的 hash 值分布更均匀

3、HashSet实现原理
	HashSet是基于HashMap来实现的，像对HashMap做了一次封装，只使用了HashMap的key来实现各种特性
	map是整个HashSet的核心，而PRESENT则是用来造一个假的value来用，Map有键和值，HashSet相当于只有键，值都是相同的固定值，即PRESENT
4、Java ReentrantLock源码，可重复锁，不可重入锁
	waite()：阻塞当前线程
	notify()：唤起被wait()阻塞的线程
	不可重入锁，即若当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会获取不到被阻塞
	重入，意味着线程可以进入它已经拥有的锁的同步代码块儿

	Lock接口提供lock和unlock方法，提供加锁和释放锁的语义
	lock方法会阻塞线程知道获取到锁，而trylock方法会立刻返回，返回true代表获取锁成功，返回false则获取不到锁

	可重入锁ReentrantLock,它的重入性表现在同一个线程可以多次获得锁，而不同线程依然不可多次获得锁，此锁分为公平锁和非公平锁，公平锁保证等待时间最长的线程将优先获得锁，非公平锁并不会保证多个线程获得锁的顺序，但并发性能表现更好，可重入锁默认使用非公平锁

	可重入公平锁获取流程：
		在获取锁的时候，如果当前线程之前已经获取到了锁，就会把state加1，在释放锁的时候会先减1，保证了同一个锁可以被同一个线程获取多次，而不会出现死锁的情况
		线程可以进入任何一个它已经获取锁的同步代码块中，最大作用就是避免死锁

		非公平锁：
			调用lock方法后，会先尝试抢占锁，在各种判断的时候会先忽略等待队列，如果锁可以，就会直接抢占使用
5、ThreadLocal是什么？场景是哪些？
	ThreadLocal是线程本地存储，在每个线程中都创建一个ThreadLocalMap对象，每个线程可以访问自己内部ThreadLocalMap对象内的value
	经典的使用场景：
		为每个线程分配一个JDBC连接Connection，这样可以保证每个线程都在各自的Connection上进行数据库的操作，不会出现A线程关了B线程正在使用的Connection,还有Session管理等问题
	正确使用：
		在finally代码块中手动清理ThreadLocal中的value，调用ThreadLocal的remove()方法，释放去value()的引用，避免内存泄漏
6、synchronized底层实现原理
	synchronized是java的内建锁，用来确保线程安全，是解决并发问题的一种重要手段，保证在多线程状态下，每次仅有一个线程访问共享资源
	作用：
		原子性
		可见性
		有序性
	语义底层是通过一个monitor的对象来完成，其实wait/notify等方法也依赖于monitor对象，只有在同步的块或方法中才能调用wait/notify等方法，否则会抛出异常，涉及两条指令：monitorenter ,monitorexit
7、synchronized和volatile区别
	作用：
		synchronized表示只有一个线程可以获取作用对象的锁，执行代码，阻塞其他线程
		volatile表示变量在CPU的寄存器中是不确定的，必须从主存中读取，保证多线程环境下变量的可见性，禁止指令重排序
	区别：
		synchronized作用于变量、方法、对象；volatile只能作用于变量
		synchronized可以保证线程间的有序性、原子性和可见性；volatile只保证可见性和有序性。无法保证原子性
		synchronized线程阻塞，volatile线程不阻塞
		volatile本质是告诉jvm当前变量在寄存器中的值是不安全的需要从内存中读取
		sychronized则是锁定当前变量，只有当前线程可以访问到该变量其他线程被阻塞
		volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化
8、synchronized和Lock区别
	实现层面不一样
		synchronized是java关键字，jvm层面实现加锁和释放锁；Lock是一个接口，在代码层面实现加锁和释放锁;Lock是一个接口，在代码层面实现加锁和释放锁
	是否自动释放锁：
		synchronized在线程代码执行完或出现异常时自动释放锁；Lock不会自动释放锁，需要再finally{}代码块显式地中释放锁
	是否一直等待：
		synchronized会导致线程拿不到锁一直等待；Lock可以设置尝试获取锁或者获取锁失败一定时间超时
	获取锁成功是否可知
		synchronized无法得知是否获取锁成功；Lock可以通过tryLock获得加锁是否成功
	功能复杂性：
		synchronized加锁可重入、不可中断、非公平；Lock可重入、可判断、可公平和不公平、细分读写锁提高效率
9、Redis介绍、方式、底层数据结构
	Redis是一款使用C语言编写的高性能key-value数据库，开源免费，遵守BSD协议
	性能高、支持数据持久化，对数据的更新采用Copy-on-write技术，可以异步地保存在磁盘上
	丰富的数据类型，String(字符串)、List(列表)、Hash(字典)、Set(集合)、Sorted Set(有序集合)
	原子性：Redis的所有操作都是原子性，多个操作通过MULTI和EXEC指令支持事务
	丰富的特性：key过期,publish/subscribe、notify
	支持数据备份，快速的主从复制
	节点集群，很容易将数据分布到多个Redis实例中
	缺点：
		数据库容易受到物理内存的限制，不能用作海量数据的高性能读写
		适合的场景主要局限在较小数据量的高性能操作和运算上
	适用场景：
		会话缓存
		全业缓存
		用作网络版集合和队
		排行榜和计数器，Redis在内存中对数字的递增、递减的操作实现的非常好。Set和Sorted Set使得在执行这些操作的时候非常简单
		发布和订阅

10、RabbitMQ的所有
	10.1：使用RabbitMQ好处：
		解藕：系统A在代码中直接调用系统B和系统C的代码，如果将来D系统接入，系统A还需要修改代码，过于麻烦，比如在网上购买商品，支付成功之后库存要减少一，如果是传统的软件架构，必须是 先支付，然后减少库存，这两个操作必须是在同一事务中，即操作原子性，但是效率低下，此时使用RabbitMQ，需要将消息发送给各自的队列来进行消息处理，支付和库存的操作之间没有关联性，这样支付和库存系统之间就进行了解藕

		异步：将消息写入消息队列，非必要的业务逻辑以异步的方式运行，加快响应速度，业务场景中，需要发出一个指示，但是并不要求立即执行，可能对什么时候执行，或者只要执行就可以了有不同的需求，而对象这样的RabbitMQ提供不同的解决方案，用户发送的消息存储在RabbitMQ中，由RabbitMQ传递给消费者来进行消费，也可以通过死信队列来实现延迟队列的效果，让消息定时被消费的鞥

		削峰：并发量大的时候，所有的请求直接怼到数据库，造成数据库连接异常，使用缓冲队列的方式，减少并发访问的压力，常见的场景是秒杀和签到系统，流量削峰两个处理方式：
				上游队列缓冲，限速发送
				下游队列缓冲，限速执行（常用，不影响客户使用的响应速度和使用体验）
			RabbitMQ中消息是通过信道Channel来传给对应的队列的，而消费端监听这个队列处理其中的消息也是有处理时间的，这时候需要解决的就是如果队列上有一定数量的消息未被确认，则不进行新的消息的消费，RabbitMQ提供channel.basicQos方法来限制信道上的消费者所能保持的最大未确认消息的数量，通过autoAck参数控制，利用RabbitMQ在服务的下游来限速执行达到流量削峰的目的

		其余好处：很容易实现集群环境的搭建，能定制路由设置消息传递的规则以及消息分步和消息缓冲等优点

	10.2：RabbitMQ中的broker、cluster是指：
		broker是一个或多个erlang node的逻辑分组，且nodee上运行着RabbitMQ的应用程序
		cluster是在broker的基础之上，增加了node之间共享元数据的约束

	10.3：消息基于什么传输，这样做优点：
		RabbitMQ基于信道Channel的方式来传输数据，排除了使用TCP链接来进行数据的传输，因为TCP链接创建和销毁对于系统性能的开销比较大，且并发能力受系统资源的限制，这样很容易造成RabbitMQ的性能瓶颈
		消费者链接RAbbitMQ其实就是一个TCP链接，一旦链接创建成功之后，就会基于链接创建Channeel，每个线程把持一个Channel,Channel复用TCP链接，减少了系统创建和销毁链接的消耗，提高了性能
	10.4：如何确保消息正确的发送到RabbitMQ
		RabbitMQ提供发送方确认机制，即消息生产者将信道设置成confirm模式，一旦信道进入confirm模式，所有在该信道上发布的消息都会指派一个唯一的id，一旦消息被投递到RabbitMQ服务中，RabbitMQ就会发送一个确认给生产者

11、垃圾回收
	java是自动化的，但是可控性差，甚至出现内存溢出的情况，即jvm分配的内存中对象过多，超出了最大可分配内存的大小
	System.gc()用于调用垃圾收集器，在调用时，垃圾收集器将运行以回收未使用的内存空间，将尝试释放被丢弃对象占用的内存
	jvm怎么确定对象应该进行回收：
		引用计数法：判断对象的引用数量
			实现方式：给对象共添加一个引用计数器，每当有引用对他进行引用时，计数器的值就加1，当引用失效，也就是不在执行此对象，她的计数器的值就减1，若某一个对象的计数器的值为0，那么表示这个对象没有人对她进行引用，就意味着是一个失效的垃圾对象，就会被gc进行回收
		可达性分析算法：判断对象的引用链是否可达来决定对象是否可以被回收
			这个算法从离散教学中的图论引用的，程序把所有的引用关系看作一张图，通过一系列的名为GC Roots的对象作为起点，从这些接待你开始向下搜索，搜索所经过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，证明此对象不可用

	jvm在什么时候进行回收：
		在cpu空闲的时候自动进行回收
		在堆内存存储满了之后
		主动调用System.gc()后尝试进行回收

	如何回收：
		标记-清除算法：
			第一个步骤 就是标记所有需要回收的对象，标记完成后就进行统一的回收掉那些带有标记的对象，优点简单，缺点效率问题，空间问题，标记清除之后会产生大量不连续的内存碎片，当程序在以后的运行过程中需要分配较大对象时无法找到足够的连续内存而造成内存空间浪费
		复制算法：
			将可用内存按容量划分为大小相等的两块，每次只使用其中的一块，当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉，这样使得每次都是对其中的一块进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，此算法的代价是将内存缩小为原来的一半

		标记-整理算法：
			标记清除算法仅对不存活的对象进行处理，剩余存活对象不做任何处理，造成内存碎片；而标记整理算法不仅对不存活对象进行处理清除，还对剩余存活对象进行整理，重新整理，因此其不会产生内存碎片
		分代收集算法
			比较智能的算法，也是现在jvm使用最多的一种算法，本身不是新的算法，而是会在具体的场景自动选择额以上三种算法进行垃圾对象回收

		1.7之前jvm把内存分为三个区域：新生代，老年代，永久代
		在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集
		老年代中因为对象存活率。高，没有额外空间对他进行分配担保，就必须用标记-清除或者额标记-整理
12、concurrentHashMap
		java.util.concurreent工具包简化并发完成，有效的减少竞争条件和死锁线程
		哪些构造函数：
			无餐构造函数
			可传初始容器大小的构造函数
			可传入map的构造函数
			可设置阀值和初始容量
			可设置初始容量和阀值和并发级别
		使用什么技术保证线程安全：
			1.7:Segment+HashEntry来进行实现的
			1.8:放弃了Segment臃肿的设计，采用Node+CAS+Synchronized来保证线程安全
		ConcurrentHashMap的get方法是否加锁：
			不需要，get方法采用了unsafe方法，来保证线程安全
		ConcurrentHashMap迭代器是强一致还是弱一致性：
			弱一致性，HashMap强一致性
			ConcurrentHashMap可以支持在迭代过程中，向map添加新元素，而HashMap则跑出了ConcurrentModificationException
			因为HashMap中包含一个修改计数器，当调用next()方法来采取下一个元素时，迭代器将会用到这个计数器
		ConcurrentHashMap1.7和1.8区别：
			jdk1.8实现降低锁的粒度，jdk1.7锁的粒度是基于Segment，包含多个HashEntry,而jdk1.8锁的粒度就是Node
			数据结构：jdk1.7Segment+HashEntry;jdk1.8数组+链表+红黑树+CAS+Synchronized
13、上线的流程
		git服务器存放代码，拉取代码，部署服务器编译代码，推送war包，tomcat服务器运行代码
14、业务的整个开发流程
		业务功能，业务流程，业务规则，界面管理，数据要求，输入，售出，费用处理要求，打印单据/文件要求，参数要求，与其他界面的整合建议

		详细讲解：
			定义本模块及其子模块的名称
			定义本模块的业务流程
			定义每个页面中的功能
			数据库设计
				针对每一个模块，分析该模块需要几张表，确定这些表间的关系，是否要引用其他表的外键
				表名与字段名要遵守开发规范
			在数据库中创建表
			在数据库中的表生成对应的尸体对象
			编写持久层、业务逻辑层、表现层代码，并在配置文件中进行相应的配置，注意包名，类名遵守开发规范
			开发完成后进行单元测试

15、多线程高并发
	
16、介绍一下自己
	我是XXX,工作XXX年，我先后在xxx公司，做过xxx项目
17、三次握手
	第一次握手：客户端将标志位SYN置1，产生随机值seq = x,并将此数据包发送给给服务器端，进入SYN_SEND状态，等待服务器端确认

  	第二次握手：服务器应用进程被动打开。若同意客户端的请求，则发回确认报文，其首部中：SYN=1,ACK=1,ack=x+1,seq=y。

	第三次握手：客户端收到确认报文之后，通知上层应用进程连接已建立，并向服务器发出确认报文，其首部：ACK=1,ack=y+1。当服务器收到客户端的确认报文之后，也通知其上层应用进程连接已建立

18、mysql数据库的优化
	选取最适用的字段属性，比如邮编号码使用char(6)就能完成任务了，应该使用MEDIUMINT而不是BIGIN来定义整型字段，尽量把字段设置为NOTNULL，这样在将来执行查询的时候，数据库不用去比较NULL值，对于某些文文本字段，例如性别，省份，将他们定义为ENUM类型，在MYsql中，ENUM类型被当作数值型数据来处理，数值型数据被处理起来的速度比文本类型快得多

	使用JOIN来代替子查询（Sub-Queries),mysql从1.4开始支持SQL子查询，这个技术 可以使用Select语句来创建一个单例的查询结果，然后把这个结果作为过滤条件用在另外一个查询中，例如，我们将客户基本信息表中没有任何订单的客户删除掉，就可以利用子查询先从销售信息表中将所有发出订单的客户ID取出，然后将结果传递给主查询，使用子查询可以一次性的完成很多逻辑上需要多个步骤才能完成的SQL操作，同时也可以避免事务或者表锁死，并且写起来也很容易，有索引的话，性能会更好，连接之所以更有效率，是因为mysql不需要在内存中创建临时表来完成这个逻辑上的需要两个步骤的查询工作

	使用联合(UNION)来代替手动创建的临时表，mysql从4.0版本开始支持union查询，它可以把需要使用临时表的两条或更多的select查询合并的一个查询中，在客户端的查询会话结束的时候，临时表会被自动删除，从而保证数据库整齐，高效

	第一个表中成功更新后，数据库突然出现意外状况，造成第二个表中的操作没有完成，这样就回造成数据的不完整，甚至会破坏数据库中的数据，避免这种情况应该使用事务，要么语句块中每条语句都操作成功，要么都失败，即可以保持数据库中数据的一致性和完整性，事务以BEDIN关键字开始，COMMIT关键字结束，在这之间的一条SQL操作失败，那么，ROLLMACK命令就可以把数据库恢复到BEGIN开始之前的状态，事务的另一个作用就是当多个用户同时使用相同的数据源的时候，它可以利用锁定数据库的方法来为用户提供一种安全的访问方式，这样可以保证用户的操作不被其他的用户所干扰

	锁定表，尽管事务是维护数据库完整性的一个非常好的方法，但却因为它的独占性，有时会影响数据库的性能，尤其是在很大的应用系统中，由于在事务执行的过程中，数据库将会被锁定，因此其他用户请求只能暂时等待直到该事务结束，有些情况下可以通过锁定表的方法来获得更好的性能
	用一个select语句取出初始数据，通过一些计算，用update语句将新值更新到表中，包含有write关键字的LOCKTABLE语句可以保证在UNLOCKTABLES命令被执行之前，不会有其他的访问来对inventory进行插入，更新或者删除的操作

	使用外键，锁定表的方法可以为树数据的完整性，但是却不能保证数据的关联性，此时可以使用外键，外键可以保证每一条销售记录都指向某一个存在的客户，在这里外键可以把customerinfo表中的CustomerID映射到salesinfo表中的CustomerID，任何一条没有合法CustomerID的记录都不会被更新或插入到salesinfo中，如果要在Mysql中使用外键，一定要在创建表的时候将表的类型定义为事务安全表InnoDB类型，定义方法是在创建表语句中加上TYPE=INNODb

	使用索引


19、mybaties传参，赋值
	传参：
		对于String类型，一般传在sql中写明parameterType="string"
		顺序传递参数：
			mapper.java：
				public User selectUser(String name,int daptId);
			mapper.xml：
				<select id="selectUser" resultType="com.po.User">
					select * from user where userName = #{0} and deptId = #{1}
				</select>
			里面的数字代表传入参数的顺序，不是特别建议使用这种方法传递参数，特别是参数个数多的时候
		注解@Param传递参数：
			mapper.java：
				public User selectUser(@Param("userName") String name,int @Param("deptId") id);
			mapper.xml文件：
				<select id="selectUser" resultType="com.po.User">
					select * from user where userName = #{userName} and deptId = #{deptId}
				</select>
			注意在xml文件中只能以@Param注解中声明的参数名称获取参数
		使用Map集合传递参数：
			mapper.java文件：
				public User selectUser(Map<String,Object> params);
			mapper.xml文件：
				<select id="selectUser" parameterType="java.util.Map" resultType="com.po.User">
					select * from user where userName = #{userName} and deptId = #{deptId}
				</select>
		使用JavaBean实体类传递参数：
			mapper.java文件：
				public User selectUser(user user);
			mapper.xml文件：
				<select id="selectUser" parameterType="com.po.User" resultType="com.po.User">
					select * from user where userName = #{userName} and deptId = #{deptId}
				</select>

	赋值：
		使用_parameter：
			public Integer test(String email );
			对应xml
 			<select id="test" resultType="java.lang.Integer">  
    			SELECT count(*) from TEUser 
    			<if test="_parameter !=null">
        			where Email = #{0}
    			</if>
			</select>
		使用Map：
			这个是万能的使用方式，不过麻烦的是，必须将参数全部包装在map里面，调用的时候将参数包装进入Map
			public Integer test(Map map);
			对应xml
			 <select id="test" resultType="java.lang.Integer">  
    			SELECT count(*) from TEUser 
    			<if test="email !=null">
        			where Email = #{0}
    			</if>
			</select>

		使用param1,param2...
			这个是第一种方式的扩展，这种方式，能轻松获取指定顺序的参数，_param后面跟的就是参数的序号，从1开始排序的
			public Integer test(String email , String name);
			对应xml
 			<select id="test" resultType="java.lang.Integer">  
    			SELECT count(*) from TEUser 
    			<if test="param1 !=null">
        			where Email = #{0}
   	 			</if>
			</select>
			此时要保证map中有key 为 email的值。

20、过滤器和拦截器的区别
	过滤器Filter：
		配置web.xml时候，总会配置下面一段设置字符编码，不然会导致乱码问题
		依赖于servlet容器，在实现上，基于函数回调，可以对几乎所有请求进行过滤，但是缺点是一个过滤器实例只能在容器初始化时调用一次，使用过滤器的目的，是用来做一些过滤操作，获取我们想要获取的数据，比如，在javaWeb中，对传入的request、response提前过滤掉一些信息，或者提前设置一些参数，然后再传入servlet或者Controller进行业务逻辑操作。通常用的场景是：在过滤器中修改字符，编码(CharacterEEncodingFilter),在过滤器中修改HttpSeervletRequest的一些参数(XSSFilter(自定义过滤器))，如：过滤低俗文件、危险字符等
	拦截器(Interceptor)：
		拦截器的配置一般在SpringMVC的配置文件中，使用Interceptors标签
		依赖于web框架，在SpringMVC中就是依赖于SpringMVC框架，在实现上，基于Java的反射机制，属于面向切面编程(AOP)的一种运用，就是在service或者一个方法前，调用一个方法或者在方法后，调用一个方法，比如动态代理就是拦截器的简单实现，在调用方法前打印出字符串(或者做其它业务逻辑的操作)，也可以在调用方法后打印出字符串，甚至在抛出异常的时候做业务逻辑的操作。由于拦截器是基于web框架的调用，因此可以使用Spring的依赖注入(DI)进行一些业务操作，同时一个拦截器实例，在一个controller生命周期之内可以多次调用， 但是缺点是只能对controller请求进行拦截，对其它的一些比如直接访问静态资源的请求则没办法进行拦截
21，权限管理
	B/S：浏览器服务
		如果不建立完整的权限检测，那么非法用户很有可能就通过浏览器轻易访问到B/S系统中的所有功能，因此B/S业务系统都需要有一个或多个权限系统来实现访问权限检测

		可以对组进行权限分配，将权限一致的人员编入同一组，然后对该组进行权限分配

		权限管理系统应该是可扩展的，它应该可以加入到任何带有权限管理功能的系统中，就像是组建一样的可以被不断的重用，而不是每开发一套管理系统，就要针对权限管理部分进行重新开发

		满足业务系统中的功能权限，传统业务系统中，存在着两种权限管理，其一是功能权限管理，另外一种则是资源权限的管理，在不同系统之间，功能权限是可以重用的，而资源权限则不能

		数据库结构也很重要的
			权限表，管理组表，人员表
			再加两张映射表：权限映射表，人员映射表，前者映射了权限表与管理组表之间的交互，后者映射了人员表与管理组表之间的交互
			另外还需要控制系统运行时左侧菜单中的权限分栏，也就是权限分栏表
	shiro权限管理：
		基本上涉及到用户参与的系统都要进行权限管理，权限管理属于系统安全的范畴，权限管理实现对用户访问系统的控制，按照安全规则或者安全策略控制用户可以访问而且只能访问自己被授权的资源

		权限管理包括用户身份认证和授权两部分，对于需要访问控制的资源用户首先经过身份认证，认证通过后用户具有该资源的访问权限方可访问

		身份认证就是判断一个用户是否为合法用户的处理过程，最简单的身份认证方式是系统通过核对用户输入的用户名和口令，看其是否与系统中存储的该用户的用户名和口令一致，来判断用户身份是否确认，对于采用指纹等系统，则出示指纹，对于硬件key等刷卡系统，则需要刷卡

		授权可以理解为who对what(which)进行how操作

		权限分为粗颗粒和细颗粒，粗颗粒权限是指对资源类型的权限，细颗粒权限是对资源实例的权限

		权限控制：
			基于角色的访问控制，以角色为中心进行访问控制，缺点以角色进行访问控制粒度较粗，系统可扩展性差
			基于资源的访问控制，系统设计时定义好查询工资的权限标识，只需要将查询工资信息权限添加到部门经理角色的权限列表中，表示判断逻辑不用修改，系统可扩展性强

		对资源类型的管理称为粗颗粒度权限管理，即只控制到菜单、按钮、方法，例如：用户具有用户管理的权限，具有导出订单明细的权限，对资源实例的控制称为细颗粒度权限管理，即控制到数据级别的权限，比如：用户只允许修改本部门的员工信息，用户只允许导出自己创建的订单明细

		细颗粒度，建议对数据级别的权限控制在业务层个性化开发，比如：用户只允许修改自己创建的商品信息可以在services接口校验实现，service接口需要传入当前操作人的 标识，与商品信息创建人标识对比 ，不一致则不允许修改商品信息

		基于url拦截，将系统操作的每个url配置在权限表中，将权限对应到角色，将角色分配给用户，用户访问系用功能通过Filter进行过滤，过滤器获取到用户访问的url，只要访问的url是用户分配角色中的url则放行继续访问

		使用springmvc拦截器对用户身份认证进行拦截，如果用户没有登陆则跳转到登陆页面，本功能也可以使用filter实现

		shiron：
		shiron是apache旗下一个开源框架，将软件系统的安全认证相关的功能抽取出来，实现用户身份认证，权限授权，加密，会话管理等功能，组成了一个通用的安全认证框架，
		可以运行在web应用,非web应用，集群分布式应用中，相对于独立
		java领域中spring security依赖于spring运行
			subject即主体，外部应用与subject进行交互，subject记录了当前操作用户，将用户的概念理解为当前操作的主体，可能是一个通过浏览器请求的用户，也可能是一个运行的程序，是一个接口
			securityManager即安全管理器，对全部的subject进行安全管理，是shiro的核心，负责对所有subject进行安全管理，是一个接口



	C/S：客户端服务
22、什么是死锁
	线程死锁是指由于两个或者多个线程互相持有所需要的资源，导致这些线程一直处于等待其他线程释放资源的状态，无法继续执行，如果线程都不主动释放所占有的资源，将产生死锁，当线程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进

	产生原因：
		持有系统不可剥夺资源，去竞争其它已被占用的系统不可剥夺资源，形成程序僵死的竞争关系
		持有资源的锁，去竞争已被占用的其他资源，形成僵死的竞争关系
		信号量使用不当
23、如何避免死锁
	并发程序一旦死锁，往往只能重启重启应用，解决死锁的最好方法就是避免死锁
	死锁发生的条件：
		互斥，共享资源只能被一个线程占用
		占有且等待，线程t1已经取得共享资源s1，尝试获取共享资源s2，不释放共享资源s1
		不可抢占，其他线程不能强行抢占线程t1占有的资源s1
		循环等待，线程t1等待线程t2占有的资源，线程t2等待线程t1占有的资源
	避免死锁的方法：
		对于以上4个条件，只要破坏其中一个条件，就可以避免死锁的发生
		对于第一个条件“互斥”是不能破坏的，因为加锁就是为了保护互斥
		其他三个条件，可以尝试：
			一次性申请所有的资源，破坏“占有且等待”条件
			占有部分资源的线程进一步申请其他资源时，如果申请不到，主动释放它占有的资源，破坏“不可抢占”条件
			按序申请资源，破坏“循环等待”条件
	编程中的最佳实践：
		使用Lock的tryLock的方法，设置超时时间，超时可以退出防止死锁
		尽量使用并发工具类代替加锁
		尽量降低锁的使用粒度
		尽量减少同步的代码块
24、css

24、solr原理
	solr是为了解决高性能的全文索引而出现的，它将用户输入的关键字进行智能 分解，分解成一个个词，过滤掉一些多余的停词及空格等，比如，“在‘，’里面‘，’也‘，’的‘，’它‘，’为‘这些词都是停止词，这些词因为使用频率过高，几乎每个网页上都存在，所有搜索引擎开发人员都将这一类词语全部忽略掉，如果网站上存在大量这样的词语，相当于浪费很多资源，然后将分解之后的词去建好的solr索引的字段中根据词的比量逐一进行匹配，最后将符合条件的数据返回给用户

	建立索引和查询的过程中，都是以基本的语素项为单位的，基本的语素项就是通过分词得到，这个过程决定了索引单元金额最终的匹配过程，分词在文本索引的建立过程和用户提交检索过程中都存在的，利用相同的分词器，把短语或者句子切分成相同的结果，才能保证检索过程顺利进行

	solr是基于Lucene的，主要用作全文检索

	涉及到服务器安装配置和客户端操作，服务端，安装就是解压一个war包，添加一些jar包，配置scheeme.xml：
		解压一个solr-4.10.3war
		拷贝example/lib/ext下的日志输出包
		配置solrhome
		配置solrhome，修改schema.xml，配置中文分词器，IK Analyzer,配置域，复制域，动态域

	solr客户端操作可以用solrj或者spring-data-solr,到时候也可以进行二次封装，也可以不需要，因都是封装给了service层，controller直接传入对象给service层就可以，客户端主要就是学会索引库的操作和各种条件的搜索，操作就是新增，删除，更新
		solrj:
		solrserver完成文档操作和搜索，solrserver,solrinputdocument,solrquery,searchresult
		spring-data-solr:
		solrtemplate完成文档操作和搜索，solrtemplate,query,criteria

	solr会考虑集群
	solr索引库在商品状态发生改变的时候(审核通过，删除)，会通过activeMQ通知更新
	solr搜索结果，可以通过redis缓存

	solr是一个独立系统，他给我们提供了很多api来操作他所连接的“数据库",可以通过api对数据库进行crud操作，而且查询操作很快
	core：理解成一个一个数据库，
	DIH（Data Import Handler)：是solr附带的用来从关系型数据库,xml，email等目标导入数据的工具，
	Filter查询：通过添加过滤条件，对查询结果进行过滤，可以多个条件连用，类似于where
	Facet查询：主要进行结果分组，有什么分组，每个分组包括多少记录，   类似于count（*）
	Group查询：类似于关系数据库的group by ，可用于一个或者几个字段去重，显示一个group的前几条记录等
	solr.xml配置core对应目录，以及名称
	schema.xml配置field相关属性，可以理解为字段，是整个core的数据结构
	db-data-config.xml或者，配置的就是数据库链接以及DIH规则，可以清晰看到哪个field是怎么生成的

	solr易于加入到web应用程序中，提供了层面搜索（就是统计）,命中醒目显示并且支持多种输出格式，易于安装和配置，而且附带一个基于HTTP的管理界面

	solr必须运行在java1.6或更高版本的java虚拟机中


25、如何并发
	乐观锁使用的场景，读不会冲突，写会冲突，同时读的频率远大于写
	

		为了更好的理解并发和同步，需要先明白两个重要概念：同步和异步
		所谓同步：理解为在执行完一个函数或方法之后，一直等待系统返回值或消息，这时程序是出于阻塞的，只有接收到返回的值或消息后才往下执行其它的命令
		所谓异步：执行完函数或方法后，不必阻塞性地等待返回值或消息，只需要向系统委托一个异步过程，那么当系统接收到返回值或消息时，系统会自动触发委托的异步过程，从而完成一个完整的流程

		同步在一定程度上可以看作是单线程，这个线程请求一个方法后就待这个方法给他回复，否则他不往下执行
		异步在一定程度上可以看做是多线程，请求一个方法后，就不管了，继续执行其他的方法

		同步就是一件事，一件事情一件事的做
		异步就是做一件事情，不影响其他事情

		同步关键字synchronized,假如这个同步的监视对象是类的话，那么如果当一个对象访问类里面的同步方法的话，那么其他的对象如果想要继续访问类里面的这个同步方法的话，就会进入阻塞，只有等前一个对象执行完该同步方法后当前对象才能够继续执行该方法，这就是同步
		相反，如果方法前没有同步关键字修饰的话，那么不同的对象可以在同一时间访问同一个方法，这就是异步

		脏数据：脏读就是指出一个事物正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事物也访问这个数据，然后使用了这个数据，因为这个数据是还没有提交的数据，那么另外一个事物读到的这个数据是脏数据，依据脏数据所做的操作可能是不正确的
		不可重复读：是指在一个事务内，多次读同一个数据，在这个事务还没有结束时，另外一个事务也访问该同一数据，那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的数据可能是不一样的，这样就发生了在一个事务内两次读到的数据是不一样的，因此称为不可重复读

		如何处理并发和同步问题主要是通过锁机制

		锁机制有2个层面：一种是代码层次上的，如java中的同步锁，典型的就是同步关键字synchronized，另外一种是数据库层次上的，比较典型的就是悲观锁和乐观锁

		悲观锁正如其名，指的是对数据被外界(包括本系统当前的其他事务，以及来自外部系统的事务处理)修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态
		悲观锁的实现：认为所有代码执行都会有并发问题，所以将所有代码块都用synchronized锁住，
		public Object get(Object obj){
			synchronized(map){
				if(map.get(key)==null){
					set some value;
				}
				return map.get(key);
			}
		}

		往往依靠数据库提供的锁机制(也只有数据库层提供的锁机制才能真正保守数据访问的排他性，否则，即时在本系统中实现了加锁机制，也无法保证外部系统不会修改数据)
		
	乐观锁：在读的时候不会产生冲突为题，在写时添加锁，所以解决的应用场景是读远大于写时的场景
		public Object get(Object obj){
			Object val = null;
			if(val = map.get(key)==null){
				//当map取值为null时再加锁判断
			synchronized(map){
				synchronized(map){
				if(map.get(key)==null){
					set some value;
				}
			}

			}
			return map.get(key);
		}


26、线程去掉k之后然后怎么样了
27、微服务

es
sougou
fengkong
hbase
hive
存储关系型 
 ''非关系型，
缓存数据，
基础加强，
缓存渗透，
sql开源，
数据结构算法，
程序算法，
稳定，
jvm，
新生代 
老年代，
永久带，
es
top
hbase如何设计
堆和栈
打日志
join连接
左连接
内连接
spring具体使用方面
get post区别
直接转发间接转发的区别
















